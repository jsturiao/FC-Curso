# Sistema de E-commerce Did√°tico com Kafka
## Plano de Implementa√ß√£o Detalhado

---

## üìã Vis√£o Geral e Objetivos

### Prop√≥sito
Criar um sistema de e-commerce simplificado que demonstre visualmente os principais conceitos e funcionalidades do Apache Kafka em um ambiente did√°tico e pr√°tico.

### Objetivos de Aprendizado
- **Arquitetura Kafka**: Brokers, t√≥picos, parti√ß√µes, replica√ß√£o
- **Padr√µes de Mensageria**: Producer/Consumer, Event Sourcing, Saga Pattern
- **Opera√ß√µes**: Schema Registry, Dead Letter Queue, Observabilidade
- **Visualiza√ß√£o**: Interface web mostrando fluxo de eventos em tempo real

### Arquitetura do Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   checkout-api  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Apache Kafka   ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ payment-service ‚îÇ
‚îÇ   (Producer)    ‚îÇ    ‚îÇ   + Kafka UI    ‚îÇ    ‚îÇ (Consumer/Prod) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ                        ‚îÇ
                              ‚ñº                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ dashboard-web   ‚îÇ    ‚îÇinventory-service‚îÇ    ‚îÇnotification-svc ‚îÇ
‚îÇ (Visualiza√ß√£o)  ‚îÇ    ‚îÇ (Consumer/Prod) ‚îÇ    ‚îÇ   (Consumer)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   PostgreSQL    ‚îÇ
                    ‚îÇ   (Persist√™ncia)‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Stack Tecnol√≥gica
- **Broker**: Apache Kafka com KRaft
- **Interface**: Kafka UI (Provectus)
- **Microservi√ßos**: Node.js + NestJS
- **Frontend**: React + Vite + WebSocket
- **Banco**: PostgreSQL
- **Observabilidade**: Prometheus + Grafana
- **Orquestra√ß√£o**: Docker Compose

---

## üó∫Ô∏è Mapa de Conceitos Kafka vs Projeto

| Conceito Kafka | Onde Aparece no Projeto | Fase |
|----------------|-------------------------|------|
| **Producers** | checkout-api criando pedidos | Fase 1 |
| **Consumers** | Todos os servi√ßos processando eventos | Fase 1 |
| **T√≥picos** | orders.new, payments.*, inventory.* | Fase 1-2 |
| **Parti√ß√µes** | Particionamento por orderId | Fase 1 |
| **Consumer Groups** | Cada servi√ßo em seu grupo | Fase 1 |
| **Schema Registry** | Evolu√ß√£o de schemas de eventos | Fase 2 |
| **Dead Letter Queue** | Tratamento de falhas | Fase 3 |
| **Idempot√™ncia** | Evitar duplica√ß√£o de pedidos | Fase 3 |
| **Transa√ß√µes** | Exactly-once delivery | Fase 3 |
| **Stream Processing** | Agrega√ß√µes e m√©tricas | Fase 4 |

---

## üöÄ Fase 0 - Fundamentos e Infraestrutura

### Etapa 0.1 - Setup do Docker Compose Base

**Objetivo**: Criar ambiente Kafka completo e funcional

#### Microfases:
1. **Configura√ß√£o do Kafka**
   - Broker √∫nico com KRaft (sem Zookeeper)
   - Configura√ß√µes de reten√ß√£o e parti√ß√µes
   - Rede Docker isolada

2. **Interface de Administra√ß√£o**
   - Kafka UI para visualiza√ß√£o
   - Configura√ß√£o de acesso web

3. **Vari√°veis de Ambiente**
   - Centraliza√ß√£o de configura√ß√µes
   - Facilitar mudan√ßas entre ambientes

**Artefatos Gerados**:
- `docker-compose.yml`
- `.env`
- `scripts/setup-topics.sh`

**Comandos Essenciais**:
```bash
# Subir ambiente
docker compose up -d

# Verificar logs do Kafka
docker compose logs kafka -f

# Criar t√≥picos iniciais
docker compose exec kafka kafka-topics --create --topic orders.new --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
```

**Crit√©rios de Aceite**:
- [ ] Kafka rodando e acess√≠vel na porta 9092
- [ ] Kafka UI acess√≠vel em http://localhost:8080
- [ ] Conseguir criar/deletar t√≥picos via UI
- [ ] Logs sem erros cr√≠ticos

---

### Etapa 0.2 - Observabilidade B√°sica

**Objetivo**: Configurar monitoramento b√°sico do cluster

#### Microfases:
1. **Prometheus + Grafana**
   - Coleta de m√©tricas do Kafka
   - Dashboards pr√©-configurados

2. **JMX Exporter**
   - Exposi√ß√£o de m√©tricas JMX do Kafka
   - Configura√ß√£o de m√©tricas relevantes

**Artefatos Gerados**:
- `monitoring/prometheus.yml`
- `monitoring/grafana-dashboards/`
- Extens√£o do `docker-compose.yml`

**Crit√©rios de Aceite**:
- [ ] Grafana acess√≠vel em http://localhost:3000
- [ ] Dashboard "Kafka Overview" funcionando
- [ ] M√©tricas b√°sicas sendo coletadas

---

### Etapa 0.3 - Schema Registry

**Objetivo**: Gerenciamento centralizado de schemas

#### Microfases:
1. **Confluent Schema Registry**
   - Container dedicado
   - Integra√ß√£o com Kafka

2. **Primeiro Schema**
   - Schema Avro para eventos de pedido
   - Teste de compatibilidade

**Artefatos Gerados**:
- `schemas/order-created.avsc`
- Scripts de registro de schemas

**Comandos Essenciais**:
```bash
# Registrar schema
curl -X POST -H "Content-Type: application/vnd.schemaregistry.v1+json" \
  --data @schemas/order-created.avsc \
  http://localhost:8081/subjects/orders.new-value/versions
```

**Crit√©rios de Aceite**:
- [ ] Schema Registry rodando na porta 8081
- [ ] Schema de pedido registrado com sucesso
- [ ] Compatibilidade BACKWARD configurada

---

## üõçÔ∏è Fase 1 - Producer/Consumer "Hello, Orders"

### Etapa 1.1 - Checkout API (Producer Principal)

**Objetivo**: Criar primeiro microservi√ßo que produz eventos

#### Microfases:
1. **Setup NestJS**
   - Projeto base com estrutura modular
   - Configura√ß√£o do cliente Kafka (KafkaJS)
   - Health check endpoints

2. **Endpoint de Checkout**
   - `POST /orders` para criar pedidos
   - Valida√ß√£o de payload (class-validator)
   - Gera√ß√£o de orderId √∫nico

3. **Produ√ß√£o de Eventos**
   - Publicar em `orders.new`
   - Chave de particionamento por orderId
   - Configura√ß√£o de idempot√™ncia

4. **Tratamento de Erros**
   - Retry autom√°tico
   - Logging estruturado
   - M√©tricas b√°sicas

**Estrutura do Projeto**:
```
checkout-api/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ orders/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ orders.controller.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ orders.service.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dto/create-order.dto.ts
‚îÇ   ‚îú‚îÄ‚îÄ kafka/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ kafka.module.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ kafka.service.ts
‚îÇ   ‚îî‚îÄ‚îÄ main.ts
‚îú‚îÄ‚îÄ package.json
‚îî‚îÄ‚îÄ docker-compose.override.yml
```

**Payload de Exemplo**:
```json
{
  "orderId": "ord_1234567890",
  "customerId": "cust_abc123",
  "items": [
    {
      "productId": "prod_xyz789",
      "quantity": 2,
      "price": 29.99
    }
  ],
  "totalAmount": 59.98,
  "timestamp": "2025-08-21T10:30:00Z"
}
```

**Configura√ß√£o Kafka**:
```typescript
// kafka.service.ts
export class KafkaService {
  private kafka = new Kafka({
    clientId: 'checkout-api',
    brokers: ['localhost:9092'],
  });

  private producer = this.kafka.producer({
    allowAutoTopicCreation: false,
    idempotent: true,
    retries: 5,
  });
}
```

**Comandos de Teste**:
```bash
# Criar pedido via API
curl -X POST http://localhost:3001/orders \
  -H "Content-Type: application/json" \
  -d '{
    "customerId": "cust_123",
    "items": [{"productId": "prod_1", "quantity": 2, "price": 25.00}]
  }'

# Verificar mensagem no t√≥pico
docker compose exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic orders.new \
  --from-beginning
```

**Crit√©rios de Aceite**:
- [ ] API rodando na porta 3001
- [ ] Endpoint POST /orders funcional
- [ ] Eventos chegando ao t√≥pico `orders.new`
- [ ] Mensagens vis√≠veis no Kafka UI
- [ ] Health check retornando status OK

---

### Etapa 1.2 - Dashboard Web (Primeira Vers√£o)

**Objetivo**: Interface visual para acompanhar eventos em tempo real

#### Microfases:
1. **Setup React + Vite**
   - Projeto frontend moderno
   - Configura√ß√£o de WebSocket
   - Componentes base

2. **Telemetry Gateway**
   - Servi√ßo Node.js intermedi√°rio
   - Consumer Kafka ‚Üí WebSocket bridge
   - Agrega√ß√£o de eventos

3. **Interface de Eventos**
   - Lista em tempo real de eventos
   - Cards visuais por tipo de evento
   - Timeline b√°sica

**Estrutura do Frontend**:
```
dashboard-web/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ EventList.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ EventCard.tsx
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ OrderTimeline.tsx
‚îÇ   ‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ useWebSocket.ts
‚îÇ   ‚îú‚îÄ‚îÄ types/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ events.ts
‚îÇ   ‚îî‚îÄ‚îÄ App.tsx
‚îî‚îÄ‚îÄ package.json
```

**Telemetry Gateway**:
```typescript
// telemetry-gateway/src/main.ts
export class TelemetryGateway {
  private consumer = this.kafka.consumer({
    groupId: 'telemetry-gateway',
  });

  async consumeEvents() {
    await this.consumer.subscribe({ 
      topics: ['orders.new', 'payments.*', 'inventory.*'] 
    });

    await this.consumer.run({
      eachMessage: async ({ topic, message }) => {
        const event = JSON.parse(message.value.toString());
        this.websocketServer.emit('event', { topic, event });
      },
    });
  }
}
```

**Crit√©rios de Aceite**:
- [ ] Dashboard acess√≠vel em http://localhost:3000
- [ ] WebSocket conectado e funcional
- [ ] Eventos aparecendo em tempo real
- [ ] Interface responsiva e intuitiva

---

### Etapa 1.3 - Payment Service (Consumer + Producer)

**Objetivo**: Primeiro servi√ßo que consome e produz eventos

#### Microfases:
1. **Setup do Servi√ßo**
   - NestJS com configura√ß√£o Kafka
   - Consumer para `orders.new`
   - Producer para `payments.*`

2. **L√≥gica de Pagamento**
   - Simula√ß√£o de processamento
   - Probabilidade configur√°vel de falha
   - Estados: pending, approved, failed

3. **Produ√ß√£o de Eventos**
   - `payments.requested` (imediato)
   - `payments.approved` ou `payments.failed` (ap√≥s delay)

**Fluxo de Eventos**:
```
orders.new ‚Üí Payment Service ‚Üí payments.requested ‚Üí [processamento] ‚Üí payments.approved/failed
```

**Consumer Configuration**:
```typescript
// payment.service.ts
@Injectable()
export class PaymentService {
  async processOrder(order: Order) {
    // 1. Publicar payment.requested
    await this.publishEvent('payments.requested', {
      orderId: order.orderId,
      amount: order.totalAmount,
      status: 'pending',
      timestamp: new Date(),
    });

    // 2. Simular processamento (1-3 segundos)
    await this.delay(Math.random() * 2000 + 1000);

    // 3. Resultado baseado em probabilidade
    const success = Math.random() > 0.2; // 80% sucesso

    const event = success ? 'payments.approved' : 'payments.failed';
    await this.publishEvent(event, {
      orderId: order.orderId,
      amount: order.totalAmount,
      status: success ? 'approved' : 'failed',
      timestamp: new Date(),
    });
  }
}
```

**Crit√©rios de Aceite**:
- [ ] Servi√ßo rodando na porta 3002
- [ ] Consumindo `orders.new` sem lag
- [ ] Publicando eventos de pagamento
- [ ] Taxa de sucesso configur√°vel funcionando
- [ ] Logs estruturados com orderId

---

## üì¶ Fase 2 - Estoque, Orquestra√ß√£o e Regras de Neg√≥cio

### Etapa 2.1 - Inventory Service

**Objetivo**: Gerenciar estoque com persist√™ncia em PostgreSQL

#### Microfases:
1. **Setup com PostgreSQL**
   - Configura√ß√£o TypeORM
   - Entidades de produto e estoque
   - Migrations iniciais

2. **Consumer de Pagamentos**
   - Escutar `payments.approved`
   - Verificar disponibilidade
   - Reservar/baixar estoque

3. **Estados do Estoque**
   - `inventory.reserved` (sucesso)
   - `inventory.failed` (sem estoque)
   - Rollback em caso de falha

**Schema do Banco**:
```sql
CREATE TABLE products (
  id VARCHAR(50) PRIMARY KEY,
  name VARCHAR(255) NOT NULL,
  stock_quantity INTEGER NOT NULL DEFAULT 0,
  reserved_quantity INTEGER NOT NULL DEFAULT 0,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE stock_movements (
  id SERIAL PRIMARY KEY,
  product_id VARCHAR(50) REFERENCES products(id),
  order_id VARCHAR(50) NOT NULL,
  movement_type VARCHAR(20) NOT NULL, -- 'reserve', 'confirm', 'release'
  quantity INTEGER NOT NULL,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**L√≥gica de Reserva**:
```typescript
@Injectable()
export class InventoryService {
  async reserveStock(orderId: string, items: OrderItem[]) {
    const queryRunner = this.dataSource.createQueryRunner();
    await queryRunner.startTransaction();

    try {
      for (const item of items) {
        const product = await queryRunner.manager.findOne(Product, {
          where: { id: item.productId },
        });

        if (!product || product.availableStock < item.quantity) {
          await this.publishEvent('inventory.failed', {
            orderId,
            reason: 'insufficient_stock',
            productId: item.productId,
          });
          throw new Error('Insufficient stock');
        }

        // Reservar estoque
        await queryRunner.manager.update(Product, 
          { id: item.productId },
          { reservedQuantity: () => 'reserved_quantity + ' + item.quantity }
        );
      }

      await queryRunner.commitTransaction();
      
      await this.publishEvent('inventory.reserved', {
        orderId,
        items,
        timestamp: new Date(),
      });

    } catch (error) {
      await queryRunner.rollbackTransaction();
    } finally {
      await queryRunner.release();
    }
  }
}
```

**Crit√©rios de Aceite**:
- [ ] PostgreSQL rodando e conectado
- [ ] Estoque sendo reservado corretamente
- [ ] Eventos de sucesso/falha publicados
- [ ] Transa√ß√µes at√¥micas funcionando
- [ ] Seeds de produtos carregados

---

### Etapa 2.2 - Orchestrator Saga

**Objetivo**: Coordenar o fluxo completo do pedido

#### Microfases:
1. **State Machine**
   - Estados do pedido: created, payment_pending, payment_approved, inventory_reserved, completed, failed
   - Transi√ß√µes baseadas em eventos
   - Timeouts para cada etapa

2. **Coordena√ß√£o de Eventos**
   - Escutar m√∫ltiplos t√≥picos
   - Correlacionar por orderId
   - Manter estado persistente

3. **Compensa√ß√£o (Saga Pattern)**
   - Rollback em caso de falha
   - Liberar estoque reservado
   - Estornar pagamento (simulado)

4. **Dead Letter Queue**
   - `orders.dlq` para casos irrecuper√°veis
   - Estrat√©gia de reprocessamento

**State Machine**:
```typescript
export enum OrderStatus {
  CREATED = 'created',
  PAYMENT_PENDING = 'payment_pending',
  PAYMENT_APPROVED = 'payment_approved',
  INVENTORY_RESERVED = 'inventory_reserved',
  COMPLETED = 'completed',
  FAILED = 'failed',
}

@Entity()
export class OrderSaga {
  @PrimaryColumn()
  orderId: string;

  @Column({ type: 'enum', enum: OrderStatus })
  status: OrderStatus;

  @Column({ type: 'json' })
  orderData: any;

  @Column({ type: 'timestamp', nullable: true })
  timeout: Date;

  @Column({ type: 'json', nullable: true })
  compensationData: any;
}
```

**L√≥gica de Orquestra√ß√£o**:
```typescript
@Injectable()
export class OrderOrchestratorService {
  async handlePaymentApproved(event: PaymentApprovedEvent) {
    const saga = await this.findSaga(event.orderId);
    
    if (saga.status === OrderStatus.PAYMENT_PENDING) {
      saga.status = OrderStatus.PAYMENT_APPROVED;
      await this.saveSaga(saga);
      
      // Pr√≥ximo passo: reservar estoque
      await this.publishEvent('inventory.reserve_request', {
        orderId: event.orderId,
        items: saga.orderData.items,
      });
    }
  }

  async handleInventoryReserved(event: InventoryReservedEvent) {
    const saga = await this.findSaga(event.orderId);
    
    if (saga.status === OrderStatus.PAYMENT_APPROVED) {
      saga.status = OrderStatus.COMPLETED;
      await this.saveSaga(saga);
      
      await this.publishEvent('orders.confirmed', {
        orderId: event.orderId,
        status: 'completed',
        timestamp: new Date(),
      });
    }
  }

  // Compensa√ß√£o em caso de falha
  async handleInventoryFailed(event: InventoryFailedEvent) {
    const saga = await this.findSaga(event.orderId);
    
    // Estornar pagamento
    await this.publishEvent('payments.refund', {
      orderId: event.orderId,
      reason: 'inventory_unavailable',
    });

    saga.status = OrderStatus.FAILED;
    await this.saveSaga(saga);
  }
}
```

**Crit√©rios de Aceite**:
- [ ] Fluxo completo funcionando (pedido ‚Üí pagamento ‚Üí estoque ‚Üí confirma√ß√£o)
- [ ] Compensa√ß√£o em caso de falha do estoque
- [ ] Timeouts sendo respeitados
- [ ] Estado persistido corretamente
- [ ] DLQ configurada e funcional

---

### Etapa 2.3 - Notification Service

**Objetivo**: Notificar clientes sobre status dos pedidos

#### Microfases:
1. **Consumer Multi-t√≥picos**
   - `orders.confirmed`
   - `orders.failed`
   - `inventory.failed`

2. **Simula√ß√£o de Notifica√ß√µes**
   - Email (log simulado)
   - SMS (log simulado)
   - Push notification (log simulado)

3. **Evento de Telemetria**
   - Publicar `notifications.sent`
   - Dados para dashboard

**Service Implementation**:
```typescript
@Injectable()
export class NotificationService {
  async sendOrderConfirmation(orderId: string, customerData: any) {
    // Simular envio de email
    this.logger.log(`üìß Email sent to ${customerData.email}: Order ${orderId} confirmed`);
    
    // Simular SMS
    this.logger.log(`üì± SMS sent to ${customerData.phone}: Your order ${orderId} is confirmed!`);
    
    await this.publishEvent('notifications.sent', {
      orderId,
      customerId: customerData.customerId,
      type: 'order_confirmation',
      channels: ['email', 'sms'],
      timestamp: new Date(),
    });
  }

  async sendOrderFailed(orderId: string, reason: string, customerData: any) {
    this.logger.log(`üìß Email sent to ${customerData.email}: Order ${orderId} failed - ${reason}`);
    
    await this.publishEvent('notifications.sent', {
      orderId,
      customerId: customerData.customerId,
      type: 'order_failed',
      channels: ['email'],
      reason,
      timestamp: new Date(),
    });
  }
}
```

**Crit√©rios de Aceite**:
- [ ] Notifica√ß√µes sendo enviadas para pedidos confirmados
- [ ] Notifica√ß√µes de falha funcionando
- [ ] Logs estruturados e leg√≠veis
- [ ] Eventos de telemetria publicados

---

### Etapa 2.4 - Dashboard Web (Vers√£o 2)

**Objetivo**: Interface visual avan√ßada com timeline e m√©tricas

#### Microfases:
1. **Timeline Visual**
   - Componente de linha do tempo por pedido
   - Estados visuais (pending, success, error)
   - Tempo decorrido entre etapas

2. **Filtros e Busca**
   - Filtrar por status
   - Buscar por orderId
   - Filtrar por per√≠odo

3. **M√©tricas em Tempo Real**
   - Taxa de sucesso
   - Tempo m√©dio de processamento
   - Pedidos por minuto

4. **Gr√°ficos Interativos**
   - Recharts para visualiza√ß√µes
   - Gr√°fico de barras (status)
   - Gr√°fico de linha (volume)

**Componentes React**:
```tsx
// OrderTimeline.tsx
export const OrderTimeline: React.FC<{ orderId: string }> = ({ orderId }) => {
  const { events } = useOrderEvents(orderId);
  
  return (
    <div className="timeline">
      {events.map((event, index) => (
        <TimelineItem 
          key={index}
          event={event}
          status={getEventStatus(event)}
          timestamp={event.timestamp}
        />
      ))}
    </div>
  );
};

// MetricsDashboard.tsx
export const MetricsDashboard: React.FC = () => {
  const { metrics } = useRealTimeMetrics();
  
  return (
    <div className="metrics-grid">
      <MetricCard 
        title="Taxa de Sucesso"
        value={`${metrics.successRate}%`}
        trend={metrics.successTrend}
      />
      <MetricCard 
        title="Tempo M√©dio"
        value={`${metrics.avgTime}s`}
        trend={metrics.timeTrend}
      />
      <BarChart data={metrics.statusDistribution} />
      <LineChart data={metrics.volumeOverTime} />
    </div>
  );
};
```

**WebSocket Events**:
```typescript
// useWebSocket.ts
export const useWebSocket = () => {
  useEffect(() => {
    const ws = new WebSocket('ws://localhost:3010/events');
    
    ws.onmessage = (event) => {
      const data = JSON.parse(event.data);
      
      switch (data.type) {
        case 'order.created':
          addEvent(data.payload);
          break;
        case 'order.updated':
          updateEvent(data.payload);
          break;
        case 'metrics.updated':
          updateMetrics(data.payload);
          break;
      }
    };
  }, []);
};
```

**Crit√©rios de Aceite**:
- [ ] Timeline visual funcionando
- [ ] Filtros operacionais
- [ ] M√©tricas atualizando em tempo real
- [ ] Gr√°ficos interativos
- [ ] Interface responsiva

---

## üõ°Ô∏è Fase 3 - Robustez Operacional

### Etapa 3.1 - Exactly-Once e Idempot√™ncia

**Objetivo**: Garantir entrega exatamente uma vez e opera√ß√µes idempotentes

#### Microfases:
1. **Transa√ß√µes Kafka**
   - Configurar EOS (Exactly-Once Semantics)
   - Transactional producers
   - Read-committed consumers

2. **Idempotent Consumers**
   - Deduplica√ß√£o por chave √∫nica
   - Tabela de controle de processamento
   - Patterns de idempot√™ncia

3. **Database Transactions**
   - Outbox pattern para publica√ß√£o de eventos
   - Transa√ß√µes distribu√≠das quando necess√°rio

**Producer Configuration**:
```typescript
// Transactional Producer
const producer = kafka.producer({
  idempotent: true,
  transactionTimeout: 30000,
});

await producer.initTransactions();

// Uso transacional
await producer.transaction(async (transaction) => {
  await transaction.send({
    topic: 'orders.confirmed',
    messages: [{
      key: orderId,
      value: JSON.stringify(orderData),
    }],
  });

  // Opera√ß√£o no banco na mesma transa√ß√£o l√≥gica
  await this.updateOrderStatus(orderId, 'confirmed');
});
```

**Idempotent Consumer Pattern**:
```typescript
@Entity()
export class ProcessedMessage {
  @PrimaryColumn()
  messageId: string;

  @Column()
  topic: string;

  @Column()
  partition: number;

  @Column()
  offset: string;

  @Column()
  processedAt: Date;
}

@Injectable()
export class IdempotentConsumerService {
  async processMessage(message: KafkaMessage) {
    const messageId = this.generateMessageId(message);
    
    // Verificar se j√° foi processado
    const processed = await this.processedMessageRepo.findOne({
      where: { messageId }
    });

    if (processed) {
      this.logger.log(`Message ${messageId} already processed, skipping`);
      return;
    }

    // Processar e marcar como processado na mesma transa√ß√£o
    await this.dataSource.transaction(async (manager) => {
      await this.businessLogic(message, manager);
      
      await manager.save(ProcessedMessage, {
        messageId,
        topic: message.topic,
        partition: message.partition,
        offset: message.offset,
        processedAt: new Date(),
      });
    });
  }
}
```

**Crit√©rios de Aceite**:
- [ ] Sem duplica√ß√£o de pedidos mesmo com retry
- [ ] Transa√ß√µes funcionando corretamente
- [ ] Tabela de controle populada
- [ ] Performance aceit√°vel com overhead

---

### Etapa 3.2 - Estrat√©gias de Retry e Backoff

**Objetivo**: Tratamento robusto de falhas tempor√°rias

#### Microfases:
1. **Retry Topics**
   - T√≥picos com delay: `orders.retry.5s`, `orders.retry.30s`, `orders.retry.5m`
   - Headers com tentativas e timestamp
   - Routing autom√°tico

2. **Exponential Backoff**
   - Delays progressivos
   - Jitter para evitar thundering herd
   - Limite m√°ximo de tentativas

3. **Poison Pill Handling**
   - Detec√ß√£o de mensagens problem√°ticas
   - Isolamento em DLQ
   - Alertas para investiga√ß√£o

**Retry Infrastructure**:
```typescript
@Injectable()
export class RetryService {
  private retryTopics = [
    { name: 'orders.retry.5s', delay: 5000 },
    { name: 'orders.retry.30s', delay: 30000 },
    { name: 'orders.retry.5m', delay: 300000 },
  ];

  async scheduleRetry(originalMessage: any, error: Error, attempt: number) {
    if (attempt >= this.retryTopics.length) {
      // M√°ximo de tentativas atingido, enviar para DLQ
      await this.sendToDLQ(originalMessage, error);
      return;
    }

    const retryTopic = this.retryTopics[attempt];
    const retryMessage = {
      ...originalMessage,
      headers: {
        ...originalMessage.headers,
        'retry-attempt': attempt.toString(),
        'retry-scheduled-at': Date.now().toString(),
        'original-error': error.message,
      },
    };

    // Agendar reprocessamento
    setTimeout(async () => {
      await this.producer.send({
        topic: retryTopic.name,
        messages: [retryMessage],
      });
    }, retryTopic.delay);
  }

  async sendToDLQ(message: any, error: Error) {
    await this.producer.send({
      topic: 'orders.dlq',
      messages: [{
        ...message,
        headers: {
          ...message.headers,
          'dlq-reason': error.message,
          'dlq-timestamp': Date.now().toString(),
        },
      }],
    });

    // Alertar equipe
    await this.alertingService.sendAlert({
      type: 'DLQ_MESSAGE',
      message: `Message sent to DLQ: ${error.message}`,
      orderId: message.orderId,
    });
  }
}
```

**Consumer com Retry**:
```typescript
@Injectable()
export class ResilientConsumerService {
  async processMessage(message: KafkaMessage) {
    try {
      await this.businessLogic(message);
    } catch (error) {
      const attempt = parseInt(message.headers['retry-attempt'] || '0');
      
      if (this.isRetryableError(error)) {
        await this.retryService.scheduleRetry(message, error, attempt + 1);
      } else {
        // Erro n√£o-recuper√°vel, enviar diretamente para DLQ
        await this.retryService.sendToDLQ(message, error);
      }
    }
  }

  private isRetryableError(error: Error): boolean {
    // Network errors, timeouts, etc.
    return error.message.includes('timeout') || 
           error.message.includes('connection') ||
           error.name === 'TemporaryError';
  }
}
```

**Crit√©rios de Aceite**:
- [ ] Retry autom√°tico funcionando
- [ ] Delays progressivos respeitados
- [ ] DLQ recebendo mensagens problem√°ticas
- [ ] Alertas sendo disparados
- [ ] Dashboard mostrando estat√≠sticas de retry

---

### Etapa 3.3 - Ensaios de Falha (Chaos Engineering)

**Objetivo**: Validar resili√™ncia do sistema sob falhas

#### Microfases:
1. **Falhas de Servi√ßo**
   - Derrubar payment-service temporariamente
   - Simular lentid√£o no inventory-service
   - Timeout no banco de dados

2. **Falhas de Schema**
   - Publicar evento com schema inv√°lido
   - Testar compatibilidade backward/forward
   - Recupera√ß√£o autom√°tica

3. **Falhas de Rede**
   - Lat√™ncia alta entre servi√ßos
   - Packet loss simulado
   - Parti√ß√µes de rede

**Scripts de Teste**:
```bash
#!/bin/bash
# chaos-tests.sh

echo "üî• Iniciando testes de caos..."

# 1. Derrubar payment-service
echo "‚è∏Ô∏è Derrubando payment-service..."
docker compose stop payment-service
sleep 30

# Verificar ac√∫mulo de lag
echo "üìä Verificando lag do consumer..."
docker compose exec kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --describe --group payment-service

# 2. Restartar servi√ßo
echo "‚ñ∂Ô∏è Restartando payment-service..."
docker compose start payment-service

# 3. Simular schema inv√°lido
echo "üö´ Enviando evento com schema inv√°lido..."
curl -X POST http://localhost:3001/orders \
  -H "Content-Type: application/json" \
  -d '{"invalidField": "this should break"}'

# 4. Simular alta carga
echo "‚ö° Simulando alta carga..."
for i in {1..100}; do
  curl -s -X POST http://localhost:3001/orders \
    -H "Content-Type: application/json" \
    -d '{"customerId": "load-test-'$i'", "items": [{"productId": "prod_1", "quantity": 1, "price": 10}]}' &
done
wait

echo "‚úÖ Testes de caos conclu√≠dos"
```

**Monitoramento Durante Testes**:
```typescript
@Injectable()
export class ChaosMonitoringService {
  async runChaosTest(testName: string, testFunction: () => Promise<void>) {
    const startTime = Date.now();
    const metrics = {
      errors: 0,
      successes: 0,
      averageLatency: 0,
    };

    try {
      await testFunction();
      
      // Coletar m√©tricas p√≥s-teste
      const endTime = Date.now();
      const duration = endTime - startTime;
      
      await this.reportChaosResults(testName, {
        ...metrics,
        duration,
        status: 'completed',
      });
      
    } catch (error) {
      await this.reportChaosResults(testName, {
        ...metrics,
        status: 'failed',
        error: error.message,
      });
    }
  }
}
```

**Crit√©rios de Aceite**:
- [ ] Sistema se recupera ap√≥s falha de servi√ßo
- [ ] Mensagens n√£o s√£o perdidas durante falhas
- [ ] DLQ funciona corretamente com schemas inv√°lidos
- [ ] M√©tricas mostram impacto e recupera√ß√£o
- [ ] Alertas s√£o disparados apropriadamente

---

### Etapa 3.4 - Observabilidade Avan√ßada

**Objetivo**: Dashboards e alertas para opera√ß√£o

#### Microfases:
1. **M√©tricas Avan√ßadas**
   - Lag por consumer group
   - Taxa de erro por servi√ßo
   - Percentis de lat√™ncia (p95, p99)
   - Throughput por t√≥pico

2. **Dashboards Grafana**
   - Overview geral do cluster
   - Drill-down por servi√ßo
   - Alertas visuais

3. **Alertas Autom√°ticos**
   - Lag alto em consumer groups
   - Taxa de erro acima do limite
   - Servi√ßos fora do ar

**Prometheus Queries**:
```yaml
# prometheus-rules.yml
groups:
  - name: kafka-alerts
    rules:
      - alert: HighConsumerLag
        expr: kafka_consumer_lag_sum > 1000
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High consumer lag detected"
          description: "Consumer group {{ $labels.group }} has lag of {{ $value }}"

      - alert: HighErrorRate
        expr: rate(kafka_consumer_errors_total[5m]) > 0.1
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "High error rate in consumer"
          description: "Error rate is {{ $value }} per second"
```

**Dashboard Configuration**:
```json
{
  "dashboard": {
    "title": "Kafka E-commerce Monitoring",
    "panels": [
      {
        "title": "Orders per Minute",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(kafka_producer_records_sent_total{topic='orders.new'}[1m]) * 60"
          }
        ]
      },
      {
        "title": "Consumer Lag",
        "type": "graph",
        "targets": [
          {
            "expr": "kafka_consumer_lag_sum"
          }
        ]
      },
      {
        "title": "Success Rate",
        "type": "stat",
        "targets": [
          {
            "expr": "(rate(orders_completed_total[5m]) / rate(orders_created_total[5m])) * 100"
          }
        ]
      }
    ]
  }
}
```

**Crit√©rios de Aceite**:
- [ ] Dashboards funcionais no Grafana
- [ ] Alertas sendo disparados corretamente
- [ ] M√©tricas precisas e atualizadas
- [ ] Drill-down por servi√ßo funcional

---

## üîÑ Fase 4 - Stream Processing Did√°tico

### Etapa 4.1 - ksqlDB para Agrega√ß√µes

**Objetivo**: Processamento de streams em tempo real

#### Microfases:
1. **Setup ksqlDB**
   - Container e configura√ß√£o
   - Conex√£o com Kafka cluster
   - Interface CLI e web

2. **Streams e Tables**
   - Stream de orders
   - Table de KPIs agregados
   - Windowing por tempo

3. **Queries em Tempo Real**
   - Contadores por status
   - M√©tricas de performance
   - Top produtos

**ksqlDB Queries**:
```sql
-- Criar stream de orders
CREATE STREAM orders_stream (
  orderId VARCHAR KEY,
  customerId VARCHAR,
  totalAmount DECIMAL(10,2),
  status VARCHAR,
  timestamp TIMESTAMP
) WITH (
  KAFKA_TOPIC='orders.new',
  VALUE_FORMAT='JSON',
  TIMESTAMP='timestamp'
);

-- Criar stream de eventos de pagamento
CREATE STREAM payments_stream (
  orderId VARCHAR KEY,
  amount DECIMAL(10,2),
  status VARCHAR,
  timestamp TIMESTAMP
) WITH (
  KAFKA_TOPIC='payments.approved',
  VALUE_FORMAT='JSON',
  TIMESTAMP='timestamp'
);

-- Agrega√ß√µes por janela de tempo
CREATE TABLE order_metrics_hourly AS
SELECT 
  TIMESTAMPTOSTRING(WINDOWSTART, 'HH:mm') as hour_start,
  COUNT(*) as total_orders,
  SUM(totalAmount) as total_revenue,
  AVG(totalAmount) as avg_order_value
FROM orders_stream 
WINDOW TUMBLING (SIZE 1 HOUR)
GROUP BY 1;

-- Top produtos por volume
CREATE TABLE top_products AS
SELECT 
  productId,
  COUNT(*) as order_count,
  SUM(quantity) as total_quantity
FROM orders_stream 
FLATTEN(items)
WINDOW TUMBLING (SIZE 1 DAY)
GROUP BY productId
HAVING COUNT(*) > 10;

-- KPIs em tempo real
CREATE TABLE live_kpis AS
SELECT 
  'global' as key,
  COUNT(*) as total_orders,
  COUNT_DISTINCT(customerId) as unique_customers,
  SUM(totalAmount) as total_revenue,
  AVG(totalAmount) as avg_order_value
FROM orders_stream 
WINDOW TUMBLING (SIZE 5 MINUTES)
GROUP BY 'global';
```

**Consumer para KPIs**:
```typescript
@Injectable()
export class KpiConsumerService {
  async consumeKpis() {
    await this.consumer.subscribe({ topics: ['LIVE_KPIS'] });
    
    await this.consumer.run({
      eachMessage: async ({ message }) => {
        const kpis = JSON.parse(message.value.toString());
        
        // Enviar para dashboard via WebSocket
        this.websocketService.broadcast('kpis.updated', kpis);
        
        // Salvar hist√≥rico
        await this.kpiRepository.save({
          timestamp: new Date(),
          totalOrders: kpis.TOTAL_ORDERS,
          uniqueCustomers: kpis.UNIQUE_CUSTOMERS,
          totalRevenue: kpis.TOTAL_REVENUE,
          avgOrderValue: kpis.AVG_ORDER_VALUE,
        });
      },
    });
  }
}
```

**Crit√©rios de Aceite**:
- [ ] ksqlDB rodando e acess√≠vel
- [ ] Streams criados e populados
- [ ] Agrega√ß√µes funcionando corretamente
- [ ] KPIs atualizando no dashboard
- [ ] Queries interativas funcionais

---

### Etapa 4.2 - Joins e Enriquecimento

**Objetivo**: Combinar dados de m√∫ltiplas fontes

#### Microfases:
1. **Customer Data Stream**
   - Simular dados de clientes
   - CDC do PostgreSQL (Debezium)
   - Table de clientes

2. **Product Catalog Stream**
   - Dados de produtos
   - Pre√ßos e descri√ß√µes
   - Atualiza√ß√µes em tempo real

3. **Stream Joins**
   - Orders + Customer data
   - Orders + Product data
   - Enriched events

**Setup Debezium (Opcional)**:
```yaml
# docker-compose.yml - Debezium connector
  debezium:
    image: debezium/connect:2.3
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: debezium
      CONFIG_STORAGE_TOPIC: debezium_configs
      OFFSET_STORAGE_TOPIC: debezium_offsets
      STATUS_STORAGE_TOPIC: debezium_status
    depends_on:
      - kafka
      - postgres
```

**ksqlDB Joins**:
```sql
-- Table de clientes
CREATE TABLE customers (
  customerId VARCHAR PRIMARY KEY,
  name VARCHAR,
  email VARCHAR,
  tier VARCHAR, -- 'bronze', 'silver', 'gold'
  registrationDate TIMESTAMP
) WITH (
  KAFKA_TOPIC='customers',
  VALUE_FORMAT='JSON'
);

-- Table de produtos
CREATE TABLE products (
  productId VARCHAR PRIMARY KEY,
  name VARCHAR,
  category VARCHAR,
  price DECIMAL(10,2),
  updatedAt TIMESTAMP
) WITH (
  KAFKA_TOPIC='products',
  VALUE_FORMAT='JSON'
);

-- Stream enriquecido
CREATE STREAM enriched_orders AS
SELECT 
  o.orderId,
  o.customerId,
  c.name as customerName,
  c.email as customerEmail,
  c.tier as customerTier,
  o.totalAmount,
  o.timestamp,
  -- Enriquecer com dados do produto seria mais complexo
  -- devido √† estrutura de array dos items
FROM orders_stream o
LEFT JOIN customers c ON o.customerId = c.customerId;

-- An√°lises por tier de cliente
CREATE TABLE revenue_by_tier AS
SELECT 
  customerTier,
  COUNT(*) as order_count,
  SUM(totalAmount) as total_revenue,
  AVG(totalAmount) as avg_order_value
FROM enriched_orders 
WINDOW TUMBLING (SIZE 1 HOUR)
GROUP BY customerTier;
```

**Crit√©rios de Aceite**:
- [ ] Dados de clientes sendo capturados
- [ ] Joins funcionando corretamente
- [ ] Eventos enriquecidos sendo produzidos
- [ ] An√°lises por segmento de cliente
- [ ] Performance aceit√°vel

---

## üé® Fase 5 - Polimento e Extens√µes

### Etapa 5.1 - Seguran√ßa B√°sica

**Objetivo**: Implementar autentica√ß√£o e autoriza√ß√£o b√°sica

#### Microfases:
1. **SASL/PLAIN**
   - Autentica√ß√£o no Kafka
   - Usu√°rios e senhas
   - ACLs b√°sicas

2. **API Authentication**
   - JWT tokens
   - Rate limiting
   - Validation middleware

3. **Secrets Management**
   - Environment variables
   - Docker secrets
   - Rotation b√°sica

**Kafka Security Config**:
```yaml
# docker-compose.yml
  kafka:
    environment:
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,SASL_PLAINTEXT:SASL_PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://localhost:9092,SASL_PLAINTEXT://localhost:9093
      KAFKA_SASL_ENABLED_MECHANISMS: PLAIN
      KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: PLAIN
      KAFKA_OPTS: "-Djava.security.auth.login.config=/etc/kafka/kafka_server_jaas.conf"
    volumes:
      - ./config/kafka_server_jaas.conf:/etc/kafka/kafka_server_jaas.conf
```

**JAAS Configuration**:
```
// kafka_server_jaas.conf
KafkaServer {
  org.apache.kafka.common.security.plain.PlainLoginModule required
  username="admin"
  password="admin-secret"
  user_admin="admin-secret"
  user_checkout="checkout-secret"
  user_payment="payment-secret";
};
```

**Client Authentication**:
```typescript
// Client com SASL
const kafka = new Kafka({
  clientId: 'checkout-api',
  brokers: ['localhost:9093'],
  sasl: {
    mechanism: 'plain',
    username: 'checkout',
    password: process.env.KAFKA_PASSWORD,
  },
});
```

**Crit√©rios de Aceite**:
- [ ] Autentica√ß√£o SASL funcionando
- [ ] ACLs configuradas por servi√ßo
- [ ] APIs protegidas com JWT
- [ ] Secrets externalizados

---

### Etapa 5.2 - Experi√™ncias Did√°ticas

**Objetivo**: Demonstra√ß√µes interativas de conceitos Kafka

#### Microfases:
1. **Partitioning Demo**
   - Interface para alterar n√∫mero de parti√ß√µes
   - Visualizar distribui√ß√£o de mensagens
   - Impacto na ordena√ß√£o

2. **Consumer Group Demo**
   - Adicionar/remover consumidores
   - Visualizar rebalanceamento
   - Lag por parti√ß√£o

3. **Schema Evolution Demo**
   - Evoluir schema em tempo real
   - Testar compatibilidade
   - Mostrar erros de incompatibilidade

**Partition Visualization**:
```tsx
// PartitionDemo.tsx
export const PartitionDemo: React.FC = () => {
  const [partitions, setPartitions] = useState(3);
  const [messages, setMessages] = useState<Message[]>([]);

  const sendTestMessage = async (key: string) => {
    const partition = hash(key) % partitions;
    
    await fetch('/api/demo/send', {
      method: 'POST',
      body: JSON.stringify({ key, partition, timestamp: Date.now() }),
    });
  };

  return (
    <div className="partition-demo">
      <div className="controls">
        <label>Parti√ß√µes: 
          <input 
            type="number" 
            value={partitions}
            onChange={(e) => setPartitions(Number(e.target.value))}
          />
        </label>
        <button onClick={() => sendTestMessage(randomKey())}>
          Enviar Mensagem
        </button>
      </div>
      
      <div className="partitions-view">
        {Array.from({ length: partitions }, (_, i) => (
          <PartitionView 
            key={i}
            partitionId={i}
            messages={messages.filter(m => m.partition === i)}
          />
        ))}
      </div>
    </div>
  );
};
```

**Consumer Group Visualization**:
```tsx
// ConsumerGroupDemo.tsx
export const ConsumerGroupDemo: React.FC = () => {
  const [consumers, setConsumers] = useState(2);
  const { partitionAssignment } = useConsumerGroupState();

  const addConsumer = () => {
    fetch('/api/demo/consumers', {
      method: 'POST',
      body: JSON.stringify({ action: 'add' }),
    });
  };

  const removeConsumer = () => {
    fetch('/api/demo/consumers', {
      method: 'POST',
      body: JSON.stringify({ action: 'remove' }),
    });
  };

  return (
    <div className="consumer-group-demo">
      <div className="controls">
        <button onClick={addConsumer}>Adicionar Consumer</button>
        <button onClick={removeConsumer}>Remover Consumer</button>
      </div>
      
      <div className="assignment-view">
        {partitionAssignment.map(assignment => (
          <ConsumerAssignmentView 
            key={assignment.consumerId}
            consumerId={assignment.consumerId}
            partitions={assignment.partitions}
            lag={assignment.lag}
          />
        ))}
      </div>
    </div>
  );
};
```

**Crit√©rios de Aceite**:
- [ ] Demo de particionamento funcional
- [ ] Visualiza√ß√£o de consumer groups
- [ ] Schema evolution interativa
- [ ] Documenta√ß√£o dos conceitos
- [ ] Interface intuitiva

---

### Etapa 5.3 - Documenta√ß√£o e Guias

**Objetivo**: Documenta√ß√£o completa para opera√ß√£o e aprendizado

#### Microfases:
1. **Runbooks Operacionais**
   - Como reprocessar DLQ
   - Troubleshooting comum
   - Procedimentos de emerg√™ncia

2. **Guias de Aprendizado**
   - Conceitos Kafka explicados
   - Exerc√≠cios pr√°ticos
   - Cen√°rios de teste

3. **API Documentation**
   - Swagger/OpenAPI
   - Exemplos de payload
   - C√≥digos de erro

**Reprocessamento de DLQ**:
```bash
#!/bin/bash
# scripts/reprocess-dlq.sh

echo "üîÑ Iniciando reprocessamento de DLQ..."

# 1. Verificar mensagens na DLQ
echo "üìä Verificando mensagens na DLQ..."
docker compose exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic orders.dlq \
  --from-beginning \
  --max-messages 10

# 2. Confirmar reprocessamento
read -p "Deseja reprocessar todas as mensagens? (y/N): " confirm
if [[ $confirm != [yY] ]]; then
  echo "Cancelado."
  exit 0
fi

# 3. Copiar DLQ para t√≥pico de reprocessamento
echo "üì§ Copiando mensagens para reprocessamento..."
docker compose exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic orders.dlq \
  --from-beginning | \
docker compose exec -T kafka kafka-console-producer \
  --bootstrap-server localhost:9092 \
  --topic orders.reprocess

# 4. Limpar DLQ ap√≥s confirma√ß√£o
read -p "Limpar DLQ ap√≥s reprocessamento? (y/N): " clear_dlq
if [[ $clear_dlq == [yY] ]]; then
  docker compose exec kafka kafka-topics \
    --bootstrap-server localhost:9092 \
    --delete --topic orders.dlq
  
  docker compose exec kafka kafka-topics \
    --bootstrap-server localhost:9092 \
    --create --topic orders.dlq \
    --partitions 1 --replication-factor 1
fi

echo "‚úÖ Reprocessamento conclu√≠do!"
```

**Troubleshooting Guide**:
```markdown
# Guia de Troubleshooting

## Problemas Comuns

### Consumer Lag Alto
**Sintomas**: Mensagens acumulando, processamento lento
**Diagn√≥stico**:
```bash
# Verificar lag por grupo
kafka-consumer-groups --bootstrap-server localhost:9092 --describe --group payment-service
```

**Solu√ß√µes**:
1. Aumentar n√∫mero de consumers
2. Otimizar processamento
3. Verificar bottlenecks no banco

### Mensagens na DLQ
**Sintomas**: Alertas de DLQ, eventos n√£o processados
**Diagn√≥stico**:
```bash
# Ver √∫ltimas mensagens na DLQ
kafka-console-consumer --bootstrap-server localhost:9092 --topic orders.dlq --from-beginning
```

**Solu√ß√µes**:
1. Investigar causa raiz no log
2. Corrigir schema se necess√°rio
3. Reprocessar usando script
```

**Crit√©rios de Aceite**:
- [ ] Documenta√ß√£o completa e atualizada
- [ ] Scripts de opera√ß√£o testados
- [ ] Guias de troubleshooting pr√°ticos
- [ ] API documentation gerada
- [ ] Exerc√≠cios pr√°ticos funcionais

---

## üìä M√©tricas de Sucesso e Valida√ß√£o

### Crit√©rios Globais de Sucesso

1. **Funcional**:
   - [ ] Fluxo completo de pedido funcionando (checkout ‚Üí confirma√ß√£o)
   - [ ] Taxa de sucesso > 95% em condi√ß√µes normais
   - [ ] Tempo m√©dio de processamento < 10 segundos
   - [ ] Zero perda de mensagens

2. **Did√°tico**:
   - [ ] Dashboard visual mostrando fluxo em tempo real
   - [ ] Conceitos Kafka claramente demonstrados
   - [ ] Documenta√ß√£o compreens√≠vel para iniciantes
   - [ ] Exerc√≠cios pr√°ticos funcionais

3. **Operacional**:
   - [ ] Observabilidade completa (m√©tricas + logs + alertas)
   - [ ] Recupera√ß√£o autom√°tica de falhas tempor√°rias
   - [ ] DLQ funcionando para casos irrecuper√°veis
   - [ ] Scripts de opera√ß√£o testados

4. **T√©cnico**:
   - [ ] C√≥digo limpo e bem estruturado
   - [ ] Testes automatizados cobrindo cen√°rios cr√≠ticos
   - [ ] Configura√ß√µes externalizadas
   - [ ] Performance aceit√°vel para fins did√°ticos

---

## üóìÔ∏è Roadmap de Entrega

### Estimativas de Esfor√ßo

| Fase | Estimativa | MVP |
|------|------------|-----|
| **Fase 0** - Infraestrutura | 2-3 dias | ‚úÖ Essencial |
| **Fase 1** - Producer/Consumer | 3-4 dias | ‚úÖ Essencial |
| **Fase 2** - Orquestra√ß√£o | 4-5 dias | ‚úÖ Essencial |
| **Fase 3** - Robustez | 3-4 dias | üî∂ Recomendado |
| **Fase 4** - Stream Processing | 2-3 dias | üî∂ Avan√ßado |
| **Fase 5** - Polimento | 2-3 dias | üî∂ Opcional |

**Total**: 16-22 dias de desenvolvimento

### Marcos Importantes

1. **MVP Did√°tico** (Fases 0-2): Sistema funcional com visualiza√ß√£o
2. **MVP Robusto** (Fases 0-3): Produ√ß√£o-ready com observabilidade
3. **MVP Avan√ßado** (Fases 0-4): Stream processing e an√°lises
4. **Vers√£o Completa** (Fases 0-5): Todos os recursos e polimento

### Ordem Recomendada

1. **Semana 1**: Fase 0 + Fase 1 (Funda√ß√£o s√≥lida)
2. **Semana 2**: Fase 2 (Fluxo completo)
3. **Semana 3**: Fase 3 (Robustez)
4. **Semana 4**: Fase 4 + Fase 5 (Recursos avan√ßados)

---

## üéØ Como Validar Cada Fase

### Checklist Geral por Fase

**Fase 0 - Valida√ß√£o**:
```bash
# Verificar se tudo est√° rodando
docker compose ps
curl http://localhost:8080  # Kafka UI
curl http://localhost:3000  # Grafana
```

**Fase 1 - Valida√ß√£o**:
```bash
# Testar fluxo b√°sico
curl -X POST http://localhost:3001/orders -d '{"customerId":"test","items":[{"productId":"prod1","quantity":1,"price":10}]}'
# Verificar no Kafka UI se mensagem chegou
# Verificar no dashboard se evento apareceu
```

**Fase 2 - Valida√ß√£o**:
```bash
# Testar fluxo completo
./scripts/test-complete-flow.sh
# Verificar no dashboard timeline completa
# Verificar m√©tricas de sucesso
```

**Fase 3 - Valida√ß√£o**:
```bash
# Testes de caos
./scripts/chaos-tests.sh
# Verificar recupera√ß√£o
# Verificar DLQ funcionando
```

**Fase 4 - Valida√ß√£o**:
```bash
# Verificar agrega√ß√µes ksqlDB
ksql http://localhost:8088
SELECT * FROM live_kpis;
```

**Fase 5 - Valida√ß√£o**:
```bash
# Testar com autentica√ß√£o
# Verificar demos interativas
# Validar documenta√ß√£o
```

---

## üìù Pr√≥ximos Passos

1. **Revisar e Aprovar Plano**: Validar escopo e estimativas
2. **Setup Inicial**: Come√ßar com Fase 0
3. **Desenvolvimento Iterativo**: Uma fase por vez com valida√ß√£o
4. **Feedback Cont√≠nuo**: Ajustar did√°tica conforme necess√°rio
5. **Documenta√ß√£o Paralela**: Manter docs atualizadas durante desenvolvimento

Este plano fornece uma estrutura s√≥lida para criar um sistema de e-commerce did√°tico que demonstra efetivamente os conceitos e opera√ß√µes do Apache Kafka, combinando aspectos pr√°ticos do dia a dia com uma abordagem visual e educativa.
